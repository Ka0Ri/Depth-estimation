model_name: 'ViT-depth estimation'
device: 'cuda:1'
batch_size: 32


training:
  lr: 0.0001
  epochs: 1

ViT-model:
  ViTconfig: "ViT-B_16"
  out_dim: 128
  pretrained: "checkpoints/ViT-B_16.npz"
  vis: False
  fine_tune: True
  n_patches: 25
  Decoder:

 
dataset:
  path: 'dataset/nyu_data.zip'
  test_path: 'dataset/nyu_test.zip'
  input_shape: (512, 512, 3)
  channel_swap: 0.5
  num_workers: 4